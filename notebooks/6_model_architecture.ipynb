{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchinfo\n",
    "\n",
    "from pitch_tracker.utils import dataset, files\n",
    "from pitch_tracker.utils.constants import (F_MIN, HOP_LENGTH, N_CLASS, N_FFT,\n",
    "                                           N_MELS, PICKING_FRAME_SIZE,\n",
    "                                           PICKING_FRAME_STEP,\n",
    "                                           PICKING_FRAME_TIME, SAMPLE_RATE,\n",
    "                                           STEP_FRAME, STEP_TIME, WIN_LENGTH)\n",
    "from pitch_tracker.utils.dataset import AudioDataset\n",
    "from pitch_tracker.ml.net import Audio_CNN, Audio_CRNN, create_conv2d_block\n",
    "from pitch_tracker.ml.train_model import train_model, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() \\\n",
    "    else \"mps\" if torch.backends.mps.is_available() \\\n",
    "    else \"cpu\"\n",
    "\n",
    "# device = \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: 66\n",
      "validation_set: 15\n",
      "test_set: 27\n"
     ]
    }
   ],
   "source": [
    "hop_size = 512\n",
    "step_frame = 2\n",
    "DATASET_DIR = f'../content/pickled_database/{hop_size}_{step_frame}/'\n",
    "DATA_SPLIT_PATH = '../pitch_tracker/utils/data_split.json'\n",
    "\n",
    "\n",
    "with open(DATA_SPLIT_PATH, 'r') as f:\n",
    "    splits = json.load(f)\n",
    "train_set = [os.path.join(DATASET_DIR, song_name) for song_name in splits['train']]\n",
    "validation_set = [os.path.join(DATASET_DIR, song_name) for song_name in splits['validation']]\n",
    "test_set = [os.path.join(DATASET_DIR, song_name) for song_name in splits['test']]\n",
    "\n",
    "print(f'train_set: {len(train_set)}')\n",
    "print(f'validation_set: {len(validation_set)}')\n",
    "print(f'test_set: {len(test_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AudioDataset(train_set)\n",
    "validation_dataset = AudioDataset(validation_set)\n",
    "test_dataset = AudioDataset(test_set)\n",
    "\n",
    "# affect GPU dedicated memory\n",
    "batch_size = 4\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Test_Model, self).__init__()\n",
    "        self.conv2d_block1 = create_conv2d_block(\n",
    "            conv2d_input=(1,128,5),\n",
    "            padding='same',\n",
    "            maxpool_kernel_size=None,\n",
    "        )\n",
    "        \n",
    "        self.conv2d_block2 = create_conv2d_block(\n",
    "            conv2d_input=(128,64,3),\n",
    "            padding='same',\n",
    "            maxpool_kernel_size=(1,5),\n",
    "        )\n",
    "\n",
    "        self.conv2d_block3 = create_conv2d_block(\n",
    "            conv2d_input=(64,64,3),\n",
    "            padding='same',\n",
    "            maxpool_kernel_size=(1,5),\n",
    "        )\n",
    "        \n",
    "        # self.conv2d_block4 = create_conv2d_block(\n",
    "        #     conv2d_input=(64,64,3),\n",
    "        #     padding='same',\n",
    "        #     maxpool_kernel_size=(1,5),\n",
    "        # )\n",
    "\n",
    "        self.flatten_layer = nn.Flatten(start_dim=2)\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=3150,\n",
    "            hidden_size=88,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        \n",
    "        # self.dense_layer = nn.LazyLinear(88)\n",
    "        # self.output_layer = nn.Linear(128, 88)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_block1(x)\n",
    "        x = self.conv2d_block2(x)\n",
    "        x = self.conv2d_block3(x)\n",
    "        # x = self.conv2d_block4(x)\n",
    "        flat = self.flatten_layer(x)\n",
    "        sequence, h_n = self.gru(flat)\n",
    "        # out = self.dense_layer(sequence)\n",
    "        # x = self.output_layer(x)\n",
    "        return sequence\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_conv2d_block' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m Test_Model()\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m dummy_in_shape \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(train_dataset\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(\u001b[39m0\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m dummy_in \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(dummy_in_shape)\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mTest_Model.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[39msuper\u001b[39m(Test_Model, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m----> 4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2d_block1 \u001b[39m=\u001b[39m create_conv2d_block(\n\u001b[1;32m      5\u001b[0m         conv2d_input\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m128\u001b[39m,\u001b[39m5\u001b[39m),\n\u001b[1;32m      6\u001b[0m         padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m         maxpool_kernel_size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m     10\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2d_block2 \u001b[39m=\u001b[39m create_conv2d_block(\n\u001b[1;32m     11\u001b[0m         conv2d_input\u001b[39m=\u001b[39m(\u001b[39m128\u001b[39m,\u001b[39m64\u001b[39m,\u001b[39m3\u001b[39m),\n\u001b[1;32m     12\u001b[0m         padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m         maxpool_kernel_size\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m5\u001b[39m),\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     16\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2d_block3 \u001b[39m=\u001b[39m create_conv2d_block(\n\u001b[1;32m     17\u001b[0m         conv2d_input\u001b[39m=\u001b[39m(\u001b[39m64\u001b[39m,\u001b[39m64\u001b[39m,\u001b[39m3\u001b[39m),\n\u001b[1;32m     18\u001b[0m         padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m         maxpool_kernel_size\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m5\u001b[39m),\n\u001b[1;32m     20\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_conv2d_block' is not defined"
     ]
    }
   ],
   "source": [
    "model = Test_Model().to('cpu')\n",
    "dummy_in_shape = [1] + list(train_dataset.__getitem__(0)[0].shape)\n",
    "dummy_in = torch.randn(dummy_in_shape)\n",
    "print(f'Input size: {tuple(dummy_in.shape)}')\n",
    "print(f'Output size: {tuple(model(dummy_in).shape)}')\n",
    "# del dummy_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Test_Model                               [4, 64, 1050, 3]          --\n",
       "├─Sequential: 1-1                        [4, 128, 1050, 88]        --\n",
       "│    └─Conv2d: 2-1                       [4, 128, 1050, 88]        3,328\n",
       "│    └─ReLU: 2-2                         [4, 128, 1050, 88]        --\n",
       "│    └─BatchNorm2d: 2-3                  [4, 128, 1050, 88]        256\n",
       "├─Sequential: 1-2                        [4, 64, 1050, 17]         --\n",
       "│    └─Conv2d: 2-4                       [4, 64, 1050, 88]         73,792\n",
       "│    └─ReLU: 2-5                         [4, 64, 1050, 88]         --\n",
       "│    └─BatchNorm2d: 2-6                  [4, 64, 1050, 88]         128\n",
       "│    └─MaxPool2d: 2-7                    [4, 64, 1050, 17]         --\n",
       "├─Sequential: 1-3                        [4, 64, 1050, 3]          --\n",
       "│    └─Conv2d: 2-8                       [4, 64, 1050, 17]         36,928\n",
       "│    └─ReLU: 2-9                         [4, 64, 1050, 17]         --\n",
       "│    └─BatchNorm2d: 2-10                 [4, 64, 1050, 17]         128\n",
       "│    └─MaxPool2d: 2-11                   [4, 64, 1050, 3]          --\n",
       "├─Flatten: 1-4                           [4, 64, 3150]             --\n",
       "==========================================================================================\n",
       "Total params: 114,560\n",
       "Trainable params: 114,560\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 31.14\n",
       "==========================================================================================\n",
       "Input size (MB): 1.48\n",
       "Forward/backward pass size (MB): 1208.52\n",
       "Params size (MB): 0.46\n",
       "Estimated Total Size (MB): 1210.46\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model, input_size=dummy_in_shape, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/Users/tien.d/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = Test_Model().to(device)\n",
    "# loss_fn = nn.BCELoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "[    1/  648]  Batch Accuracy: 6.2%, current loss: 13.060298\n",
      "[   50/  648]  Batch Accuracy: 0.0%, current loss: 641.974011\n",
      "[   99/  648]  Batch Accuracy: 0.5%, current loss: 1269.609948\n",
      "[  148/  648]  Batch Accuracy: 0.0%, current loss: 1896.429015\n",
      "[  197/  648]  Batch Accuracy: 0.0%, current loss: 2522.489054\n",
      "[  246/  648]  Batch Accuracy: 0.0%, current loss: 3148.550686\n",
      "[  295/  648]  Batch Accuracy: 1.4%, current loss: 3774.858865\n",
      "[  344/  648]  Batch Accuracy: 1.4%, current loss: 4400.766545\n",
      "[  393/  648]  Batch Accuracy: 1.0%, current loss: 5026.630705\n",
      "[  442/  648]  Batch Accuracy: 0.0%, current loss: 5653.060153\n",
      "[  491/  648]  Batch Accuracy: 0.0%, current loss: 6279.430711\n",
      "[  540/  648]  Batch Accuracy: 1.0%, current loss: 6904.975354\n",
      "[  589/  648]  Batch Accuracy: 0.0%, current loss: 7530.056245\n",
      "[  638/  648]  Batch Accuracy: 0.0%, current loss: 8155.244347\n",
      "[  648/  648]  Total Accuracy: 2.9%, Avg loss: 12.781859\n",
      "Test Error: \n",
      " Accuracy: 7.9%, Avg loss: 12.775410 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[    1/  648]  Batch Accuracy: 5.7%, current loss: 12.732586\n",
      "[   50/  648]  Batch Accuracy: 1.9%, current loss: 636.010792\n",
      "[   99/  648]  Batch Accuracy: 15.2%, current loss: 1261.474238\n",
      "[  148/  648]  Batch Accuracy: 0.0%, current loss: 1885.896948\n",
      "[  197/  648]  Batch Accuracy: 1.9%, current loss: 2509.974974\n",
      "[  246/  648]  Batch Accuracy: 20.0%, current loss: 3133.821954\n",
      "[  295/  648]  Batch Accuracy: 1.0%, current loss: 3758.249295\n",
      "[  344/  648]  Batch Accuracy: 16.2%, current loss: 4380.780211\n",
      "[  393/  648]  Batch Accuracy: 2.4%, current loss: 5005.056330\n",
      "[  442/  648]  Batch Accuracy: 1.9%, current loss: 5629.911627\n",
      "[  491/  648]  Batch Accuracy: 0.5%, current loss: 6254.119195\n",
      "[  540/  648]  Batch Accuracy: 0.0%, current loss: 6877.841961\n",
      "[  589/  648]  Batch Accuracy: 9.0%, current loss: 7501.339858\n",
      "[  638/  648]  Batch Accuracy: 15.2%, current loss: 8123.633852\n",
      "[  648/  648]  Total Accuracy: 11.1%, Avg loss: 12.733689\n",
      "Test Error: \n",
      " Accuracy: 16.8%, Avg loss: 12.841370 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[    1/  648]  Batch Accuracy: 11.0%, current loss: 12.679253\n",
      "[   50/  648]  Batch Accuracy: 1.4%, current loss: 634.861170\n",
      "[   99/  648]  Batch Accuracy: 25.2%, current loss: 1257.053933\n",
      "[  148/  648]  Batch Accuracy: 28.1%, current loss: 1878.128170\n",
      "[  197/  648]  Batch Accuracy: 16.7%, current loss: 2498.001874\n",
      "[  246/  648]  Batch Accuracy: 3.3%, current loss: 3120.616410\n",
      "[  295/  648]  Batch Accuracy: 0.5%, current loss: 3741.851699\n",
      "[  344/  648]  Batch Accuracy: 1.9%, current loss: 4364.626686\n",
      "[  393/  648]  Batch Accuracy: 1.9%, current loss: 4985.296106\n",
      "[  442/  648]  Batch Accuracy: 3.3%, current loss: 5607.770753\n",
      "[  491/  648]  Batch Accuracy: 19.0%, current loss: 6227.920678\n",
      "[  540/  648]  Batch Accuracy: 10.0%, current loss: 6850.854017\n",
      "[  589/  648]  Batch Accuracy: 1.9%, current loss: 7473.652807\n",
      "[  638/  648]  Batch Accuracy: 3.8%, current loss: 8095.544356\n",
      "[  648/  648]  Total Accuracy: 15.5%, Avg loss: 12.688634\n",
      "Test Error: \n",
      " Accuracy: 17.6%, Avg loss: 12.787212 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[    1/  648]  Batch Accuracy: 0.5%, current loss: 12.636801\n",
      "[   50/  648]  Batch Accuracy: 7.1%, current loss: 630.691287\n",
      "[   99/  648]  Batch Accuracy: 14.3%, current loss: 1249.826701\n",
      "[  148/  648]  Batch Accuracy: 20.5%, current loss: 1866.342529\n",
      "[  197/  648]  Batch Accuracy: 0.0%, current loss: 2484.986111\n",
      "[  246/  648]  Batch Accuracy: 19.5%, current loss: 3102.756210\n",
      "[  295/  648]  Batch Accuracy: 17.1%, current loss: 3724.645131\n",
      "[  344/  648]  Batch Accuracy: 3.8%, current loss: 4346.746807\n",
      "[  393/  648]  Batch Accuracy: 10.5%, current loss: 4966.074415\n",
      "[  442/  648]  Batch Accuracy: 10.5%, current loss: 5585.423469\n",
      "[  491/  648]  Batch Accuracy: 13.3%, current loss: 6204.253271\n",
      "[  540/  648]  Batch Accuracy: 88.1%, current loss: 6826.613019\n",
      "[  589/  648]  Batch Accuracy: 47.6%, current loss: 7447.374155\n",
      "[  638/  648]  Batch Accuracy: 1.0%, current loss: 8067.179813\n",
      "[  648/  648]  Total Accuracy: 15.4%, Avg loss: 12.643786\n",
      "Test Error: \n",
      " Accuracy: 18.8%, Avg loss: 12.989635 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[    1/  648]  Batch Accuracy: 38.1%, current loss: 12.532924\n",
      "[   50/  648]  Batch Accuracy: 34.3%, current loss: 626.257187\n",
      "[   99/  648]  Batch Accuracy: 1.4%, current loss: 1244.133220\n",
      "[  148/  648]  Batch Accuracy: 12.4%, current loss: 1861.405732\n",
      "[  197/  648]  Batch Accuracy: 22.9%, current loss: 2478.305085\n",
      "[  246/  648]  Batch Accuracy: 16.2%, current loss: 3093.101477\n",
      "[  295/  648]  Batch Accuracy: 12.9%, current loss: 3710.210399\n",
      "[  344/  648]  Batch Accuracy: 20.5%, current loss: 4329.406853\n",
      "[  393/  648]  Batch Accuracy: 10.0%, current loss: 4947.615245\n",
      "[  442/  648]  Batch Accuracy: 0.5%, current loss: 5564.017236\n",
      "[  491/  648]  Batch Accuracy: 11.4%, current loss: 6181.261605\n",
      "[  540/  648]  Batch Accuracy: 8.6%, current loss: 6798.273758\n",
      "[  589/  648]  Batch Accuracy: 100.0%, current loss: 7413.910154\n",
      "[  638/  648]  Batch Accuracy: 11.0%, current loss: 8033.598277\n",
      "[  648/  648]  Total Accuracy: 20.2%, Avg loss: 12.593157\n",
      "Test Error: \n",
      " Accuracy: 13.4%, Avg loss: 12.847432 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_model(model, validation_dataloader,loss_fn, optimizer, device)\n",
    "    test_model(model, test_dataloader, loss_fn, device)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 0.300722 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(model, validation_dataloader, loss_fn, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, (y1,y2,y3) = next(iter(train_dataloader))\n",
    "X = X.to(device)\n",
    "y3 = y3.to(device)\n",
    "y_pred = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2972,  0.3336, -0.1609,  ..., -0.0524, -0.0204, -0.8517],\n",
       "         [-0.1902,  0.0582,  0.1809,  ...,  0.0170,  0.2186, -0.5805],\n",
       "         [-0.3692, -0.0507,  0.0995,  ..., -0.0526,  0.0991, -0.6397],\n",
       "         ...,\n",
       "         [-0.5017, -0.3042, -0.5330,  ..., -0.0360, -0.4683,  0.2623],\n",
       "         [-0.4445,  0.0660, -0.5317,  ..., -0.0100, -0.4262,  0.6025],\n",
       "         [-0.2346, -0.5030, -0.2007,  ..., -0.0692,  0.0729, -0.1966]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(y_pred, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.041638374328613"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 210, 88])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.size()\n",
    "y3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73920"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([840])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.argmax(2).flatten() == y3.argmax(2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred.argmax(2) == y3.argmax(2)).type(torch.float).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_matrix = (y_pred.argmax(2) == y3.argmax(2)).flatten()\n",
    "n_size = pos_neg_matrix.numel()\n",
    "n_correct = torch.nonzero(pos_neg_matrix).numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20230310-171903'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "date_time = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3071ef67f0d52b8c9e2a13540b1ce413279ebac2bba14c7b121f8f9e6920f86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
